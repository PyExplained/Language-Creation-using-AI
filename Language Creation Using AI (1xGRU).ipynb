{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language Creation Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"eng_sentences.tsv\"\n",
    "with open(filepath, encoding=\"utf-8\") as f:\n",
    "    english_sentences = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_samples = 200000  # number of sentences loaded during preprocessing\n",
    "tokenizer_samples = 10000  # number of sentences to fit the tokenizer on\n",
    "num_sentences = 40000  # number of sentences used during training\n",
    "max_sentence_len = 12  # words\n",
    "\n",
    "english_sentences = [sentence[sentence.index(\"\\t\")+5:-1] for sentence in english_sentences if len(sentence[sentence.index(\"\\t\")+5:-1].split()) <= max_sentence_len][:load_samples]\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(english_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_id = 1500  # vocabulary size\n",
    "tokenizer = keras.preprocessing.text.Tokenizer(num_words=max_id, oov_token='OOV')\n",
    "tokenizer.fit_on_texts(english_sentences[:tokenizer_samples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[168]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.texts_to_sequences([\"First\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['first']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.sequences_to_texts([[168]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = tokenizer.texts_to_sequences(english_sentences)\n",
    "indexes = [1 not in x and len(x) <= max_sentence_len for x in tokenized]  # No sentences with oov-words\n",
    "tokenized = np.array(tokenized, dtype=object)[indexes][:num_sentences]\n",
    "english_sentences = np.array(english_sentences, dtype=object)[indexes][:num_sentences]\n",
    "\n",
    "encoded = tf.keras.preprocessing.sequence.pad_sequences([x for x in tokenized if not 1 in x], padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "X_train, X_val, _, _ = train_test_split(encoded, encoded, test_size=0.1, random_state=42)\n",
    "X_train_dataset = tf.data.Dataset.from_tensor_slices(X_train)\n",
    "X_train_dataset = X_train_dataset.batch(batch_size)\n",
    "ae_training_dataset = X_train_dataset.map(lambda X_batch: (X_batch, tf.one_hot(X_batch, depth=max_id)))\n",
    "\n",
    "X_val_dataset = tf.data.Dataset.from_tensor_slices(X_val)\n",
    "X_val_dataset = X_val_dataset.batch(batch_size)\n",
    "ae_validation_dataset = X_val_dataset.map(lambda X_batch: (X_batch, tf.one_hot(X_batch, depth=max_id)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_decoder_model_file = r\"Trained Model1 (1xGRU)/encoder_decoder_model.hdf5\"\n",
    "eng2lang_model_file = r\"Trained Model1 (1xGRU)/eng2lang_model.hdf5\"\n",
    "lang2eng_model_file = r\"Trained Model1 (1xGRU)/lang2eng_model.hdf5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder / Decoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_encoder_decoder_model(regularization=False, load_weights=None):\n",
    "    reg = None\n",
    "    if regularization:\n",
    "        reg = keras.regularizers.l1_l2(1e-3)\n",
    "    \n",
    "    model_inputs = keras.Input(shape=(max_sentence_len), name=\"inputs\")\n",
    "    model_embedding = keras.layers.Embedding(max_id, 16, name=\"embed\")(model_inputs)\n",
    "\n",
    "    model_gru = keras.layers.Bidirectional(keras.layers.GRU(256, return_sequences=True, kernel_regularizer=reg), name=\"gru\")(model_embedding)\n",
    "    model_outputs = keras.layers.TimeDistributed(keras.layers.Dense(max_id, activation=\"softmax\", \n",
    "                                                                     kernel_regularizer=reg, name=\"outputs\"))(model_gru)\n",
    "    \n",
    "    model = keras.Model(inputs=model_inputs, outputs=model_outputs)\n",
    "    \n",
    "    if load_weights:\n",
    "        model.load_weights(load_weights)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          [(None, 12)]              0         \n",
      "_________________________________________________________________\n",
      "embed (Embedding)            (None, 12, 16)            24000     \n",
      "_________________________________________________________________\n",
      "gru (Bidirectional)          (None, 12, 512)           420864    \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 12, 1500)          769500    \n",
      "=================================================================\n",
      "Total params: 1,214,364\n",
      "Trainable params: 1,214,364\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_decoder_model = generate_encoder_decoder_model(regularization=False)\n",
    "encoder_decoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1125/1125 [==============================] - 52s 44ms/step - loss: 1.8952 - accuracy: 0.7034 - val_loss: 0.2877 - val_accuracy: 0.9573\n",
      "Epoch 2/3\n",
      "1125/1125 [==============================] - 48s 43ms/step - loss: 0.0881 - accuracy: 0.9887 - val_loss: 0.0210 - val_accuracy: 0.9980\n",
      "Epoch 3/3\n",
      "1125/1125 [==============================] - 48s 43ms/step - loss: 0.0074 - accuracy: 0.9996 - val_loss: 0.0060 - val_accuracy: 0.9994\n"
     ]
    }
   ],
   "source": [
    "encoder_decoder_model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "encoder_decoder_model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=encoder_decoder_model_file,\n",
    "    monitor='accuracy',\n",
    "    mode='max',\n",
    "    save_freq=\"epoch\",\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True)\n",
    "\n",
    "history = encoder_decoder_model.fit(ae_training_dataset, epochs=3, callbacks=[encoder_decoder_model_checkpoint_callback], \n",
    "                                    validation_data=ae_validation_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eng2Lang Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training with regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1125/1125 [==============================] - 56s 48ms/step - loss: 40.7996 - accuracy: 0.7673 - val_loss: 7.7005 - val_accuracy: 0.6826\n",
      "Epoch 2/3\n",
      "1125/1125 [==============================] - 56s 50ms/step - loss: 4.5282 - accuracy: 0.6736 - val_loss: 3.3356 - val_accuracy: 0.6597\n",
      "Epoch 3/3\n",
      "1125/1125 [==============================] - 53s 47ms/step - loss: 3.1708 - accuracy: 0.6688 - val_loss: 3.0865 - val_accuracy: 0.6715\n"
     ]
    }
   ],
   "source": [
    "eng2lang_model = generate_encoder_decoder_model(regularization=True, load_weights=encoder_decoder_model_file)\n",
    "eng2lang_model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "eng2lang_model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=eng2lang_model_file,\n",
    "    monitor='accuracy',\n",
    "    mode='max',\n",
    "    save_freq=\"epoch\",\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True)\n",
    "history = eng2lang_model.fit(ae_training_dataset, epochs=3, callbacks=[eng2lang_model_checkpoint_callback], \n",
    "                             validation_data=ae_validation_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rehabilitation phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 5s 190ms/step - loss: 2.1505 - accuracy: 0.7010 - val_loss: 2.0526 - val_accuracy: 0.7097\n"
     ]
    }
   ],
   "source": [
    "eng2lang_model = generate_encoder_decoder_model(regularization=False, load_weights=eng2lang_model_file)\n",
    "eng2lang_model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "eng2lang_model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=eng2lang_model_file,\n",
    "    monitor='accuracy',\n",
    "    mode='max',\n",
    "    save_freq=\"epoch\",\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True)\n",
    "history = eng2lang_model.fit(ae_training_dataset.take(15), epochs=1, callbacks=[eng2lang_model_checkpoint_callback], \n",
    "                             validation_data=ae_validation_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lang2Eng Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_training_dataset2 = X_train_dataset.map(lambda X_batch: (tf.argmax(eng2lang_model(X_batch), axis=-1), tf.one_hot(X_batch, depth=max_id)))\n",
    "ae_validation_dataset2 = X_val_dataset.map(lambda X_batch: (tf.argmax(eng2lang_model(X_batch), axis=-1), tf.one_hot(X_batch, depth=max_id)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1125/1125 [==============================] - 75s 65ms/step - loss: 1.3089 - accuracy: 0.7462 - val_loss: 1.1292 - val_accuracy: 0.7621\n",
      "Epoch 2/25\n",
      "1125/1125 [==============================] - 75s 67ms/step - loss: 1.0269 - accuracy: 0.7748 - val_loss: 1.0484 - val_accuracy: 0.7758\n",
      "Epoch 3/25\n",
      "1125/1125 [==============================] - 74s 65ms/step - loss: 0.9119 - accuracy: 0.7926 - val_loss: 1.0149 - val_accuracy: 0.7815\n",
      "Epoch 4/25\n",
      "1125/1125 [==============================] - 73s 65ms/step - loss: 0.8192 - accuracy: 0.8085 - val_loss: 1.0028 - val_accuracy: 0.7841\n",
      "Epoch 5/25\n",
      "1125/1125 [==============================] - 76s 68ms/step - loss: 0.7374 - accuracy: 0.8235 - val_loss: 1.0022 - val_accuracy: 0.7852\n",
      "Epoch 6/25\n",
      "1125/1125 [==============================] - 75s 67ms/step - loss: 0.6627 - accuracy: 0.8382 - val_loss: 1.0096 - val_accuracy: 0.7867\n",
      "Epoch 7/25\n",
      "1125/1125 [==============================] - 73s 65ms/step - loss: 0.5940 - accuracy: 0.8531 - val_loss: 1.0242 - val_accuracy: 0.7868\n",
      "Epoch 8/25\n",
      "1125/1125 [==============================] - 74s 65ms/step - loss: 0.5308 - accuracy: 0.8680 - val_loss: 1.0448 - val_accuracy: 0.7856\n",
      "Epoch 9/25\n",
      "1125/1125 [==============================] - 75s 66ms/step - loss: 0.4730 - accuracy: 0.8824 - val_loss: 1.0687 - val_accuracy: 0.7842\n",
      "Epoch 10/25\n",
      "1125/1125 [==============================] - 73s 65ms/step - loss: 0.4206 - accuracy: 0.8963 - val_loss: 1.0965 - val_accuracy: 0.7835\n",
      "Epoch 11/25\n",
      "1125/1125 [==============================] - 74s 66ms/step - loss: 0.3736 - accuracy: 0.9094 - val_loss: 1.1271 - val_accuracy: 0.7826\n",
      "Epoch 12/25\n",
      "1125/1125 [==============================] - 74s 66ms/step - loss: 0.3316 - accuracy: 0.9208 - val_loss: 1.1578 - val_accuracy: 0.7818\n",
      "Epoch 13/25\n",
      "1125/1125 [==============================] - 74s 65ms/step - loss: 0.2950 - accuracy: 0.9314 - val_loss: 1.1873 - val_accuracy: 0.7818\n",
      "Epoch 14/25\n",
      "1125/1125 [==============================] - 73s 65ms/step - loss: 0.2643 - accuracy: 0.9394 - val_loss: 1.2182 - val_accuracy: 0.7811\n",
      "Epoch 15/25\n",
      "1125/1125 [==============================] - 75s 67ms/step - loss: 0.2391 - accuracy: 0.9460 - val_loss: 1.2492 - val_accuracy: 0.7802\n",
      "Epoch 16/25\n",
      "1125/1125 [==============================] - 73s 65ms/step - loss: 0.2189 - accuracy: 0.9506 - val_loss: 1.2773 - val_accuracy: 0.7794\n",
      "Epoch 17/25\n",
      "1125/1125 [==============================] - 73s 65ms/step - loss: 0.2017 - accuracy: 0.9547 - val_loss: 1.3114 - val_accuracy: 0.7774\n",
      "Epoch 18/25\n",
      "1125/1125 [==============================] - 73s 65ms/step - loss: 0.1866 - accuracy: 0.9577 - val_loss: 1.3380 - val_accuracy: 0.7761\n",
      "Epoch 19/25\n",
      "1125/1125 [==============================] - 74s 65ms/step - loss: 0.1728 - accuracy: 0.9609 - val_loss: 1.3684 - val_accuracy: 0.7753\n",
      "Epoch 20/25\n",
      "1125/1125 [==============================] - 73s 65ms/step - loss: 0.1613 - accuracy: 0.9633 - val_loss: 1.3903 - val_accuracy: 0.7756\n",
      "Epoch 21/25\n",
      "1125/1125 [==============================] - 73s 65ms/step - loss: 0.1511 - accuracy: 0.9657 - val_loss: 1.4175 - val_accuracy: 0.7754\n",
      "Epoch 22/25\n",
      "1125/1125 [==============================] - 73s 65ms/step - loss: 0.1431 - accuracy: 0.9670 - val_loss: 1.4382 - val_accuracy: 0.7740\n",
      "Epoch 23/25\n",
      "1125/1125 [==============================] - 76s 68ms/step - loss: 0.1374 - accuracy: 0.9678 - val_loss: 1.4572 - val_accuracy: 0.7759\n",
      "Epoch 24/25\n",
      "1125/1125 [==============================] - 74s 66ms/step - loss: 0.1302 - accuracy: 0.9694 - val_loss: 1.4818 - val_accuracy: 0.7732\n",
      "Epoch 25/25\n",
      "1125/1125 [==============================] - 73s 65ms/step - loss: 0.1254 - accuracy: 0.9697 - val_loss: 1.5028 - val_accuracy: 0.7726\n"
     ]
    }
   ],
   "source": [
    "lang2eng_model = generate_encoder_decoder_model(regularization=False, load_weights=encoder_decoder_model_file)\n",
    "\n",
    "lang2eng_model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "lang2eng_model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=lang2eng_model_file,\n",
    "    monitor='accuracy',\n",
    "    mode='max',\n",
    "    save_freq=\"epoch\",\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True)\n",
    "history = lang2eng_model.fit(ae_training_dataset2, epochs=25, callbacks=[lang2eng_model_checkpoint_callback], \n",
    "                             validation_data=ae_validation_dataset2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAx8ElEQVR4nO3dd5xU9b3/8ddne4dld+kd6RbKAhaMGEtQo9gigg0b1lhickMS89NrTGK8KTcaYwcFEcUaoiZEFFGvUpYmvZddyjbYztb5/P44Z9lhWWCAnZ2dmc/z8ZjHnDrzOTsw7/me7ymiqhhjjDHHEhHoAowxxgQHCwxjjDE+scAwxhjjEwsMY4wxPrHAMMYY4xMLDGOMMT6xwDAGEJHXRORJH5fdLiIX+rsmY1obCwxjjDE+scAwJoSISFSgazChywLDBA13V9DPROQ7ESkXkVdFpIOI/EtESkVknoikei1/hYisEZEiEflCRAZ6zRsqIsvc9d4G4hq91w9FZIW77jcicrqPNV4mIstFpEREskXk8UbzR7uvV+TOn+ROjxeRP4nIDhEpFpGv3WljRCSnib/Dhe7w4yLyroi8ISIlwCQRGSki37rvsUdE/iYiMV7rDxaRT0Vkn4jkisgvRaSjiFSISJrXcsNEJF9Eon3ZdhP6LDBMsLkGuAjoB1wO/Av4JZCB8+/5AQAR6QfMAh5y530C/FNEYtwvzw+BGUA74B33dXHXHQpMBe4C0oAXgTkiEutDfeXAzUBb4DLgHhG50n3dHm69z7o1DQFWuOv9ERgOnO3W9F+Ax8e/yTjgXfc9ZwJ1wMNAOnAWcAFwr1tDMjAP+DfQGTgF+ExV9wJfANd5ve5NwFuqWuNjHSbEWWCYYPOsquaq6i7gK2CRqi5X1UrgA2Cou9x44GNV/dT9wvsjEI/zhXwmEA38r6rWqOq7wBKv95gMvKiqi1S1TlVfB6rc9Y5KVb9Q1VWq6lHV73BC6zx39kRgnqrOct+3UFVXiEgEcBvwoKruct/zG1Wt8vFv8q2qfui+5wFVXaqqC1W1VlW34wRefQ0/BPaq6p9UtVJVS1V1kTvvdeBGABGJBCbghKoxgAWGCT65XsMHmhhPcoc7AzvqZ6iqB8gGurjzdumhV97c4TXcA3jE3aVTJCJFQDd3vaMSkVEiMt/dlVMM3I3zSx/3NbY0sVo6zi6xpub5IrtRDf1E5CMR2evupvqdDzUA/AMYJCK9cFpxxaq6+ARrMiHIAsOEqt04X/wAiIjgfFnuAvYAXdxp9bp7DWcDv1XVtl6PBFWd5cP7vgnMAbqpahvgBaD+fbKBPk2sUwBUHmFeOZDgtR2ROLuzvDW+5PTzwHqgr6qm4Oyy866hd1OFu6202TitjJuw1oVpxALDhKrZwGUicoHbafsIzm6lb4BvgVrgARGJFpGrgZFe674M3O22FkREEt3O7GQf3jcZ2KeqlSIyEmc3VL2ZwIUicp2IRIlImogMcVs/U4E/i0hnEYkUkbPcPpONQJz7/tHAo8Cx+lKSgRKgTEQGAPd4zfsI6CQiD4lIrIgki8gor/nTgUnAFVhgmEYsMExIUtUNOL+Un8X5BX85cLmqVqtqNXA1zhfjPpz+jve91s0C7gT+BuwHNrvL+uJe4AkRKQX+H05w1b/uTuBSnPDah9PhfYY7+6fAKpy+lH3AH4AIVS12X/MVnNZROXDIUVNN+ClOUJXihN/bXjWU4uxuuhzYC2wCzvea/384ne3LVNV7N50xiN1AyRjjTUQ+B95U1VcCXYtpXSwwjDEHicgI4FOcPpjSQNdjWhfbJWWMAUBEXsc5R+MhCwvTFGthGGOM8Ym1MIwxxvgkZC5Ulp6erj179gx0GcYYE1SWLl1aoKqNz+1pUsgERs+ePcnKygp0GcYYE1RExOfDp22XlDHGGJ9YYBhjjPGJBYYxxhifhEwfRlNqamrIycmhsrIy0KX4XVxcHF27diU62u51Y4zxj5AOjJycHJKTk+nZsyeHXpg0tKgqhYWF5OTk0KtXr0CXY4wJUSG9S6qyspK0tLSQDgsAESEtLS0sWlLGmMAJ6cAAQj4s6oXLdhpjAiekd0kZY0ywOFBdx57iAxSUVVNT56G6zkNtnVJT53EfSq3XcE2dh1qPUl3roUNKHBNHdT/2m5wkCww/Kyoq4s033+Tee+89rvUuvfRS3nzzTdq2beufwowxLeZAdR17SyrZU3SAPcWV7Cmuf648OF5UUXPCrz+se1sLjFBQVFTE3//+98MCo7a2lqioI//5P/nkE3+XZozxkapSUllLcUUNJZU1lFXVUlpZS1lVDaWVtV6Phnmllc683JJK9jcRBqkJ0XRqE0/nNnEM79GWTm3i6dQmjozkWGIiI4iOiiA6IoLoKCEqIoKYyAiiIoXoyEOHoyKEiIiW2SVtgeFnU6ZMYcuWLQwZMoTo6Gji4uJITU1l/fr1bNy4kSuvvJLs7GwqKyt58MEHmTx5MtBwqZOysjIuueQSRo8ezTfffEOXLl34xz/+QXx8fIC3zJjg5vEo+yuqKSyvpqC0ivyyKgrKqikoq6KgtMp5Lqum0H2urvMc9fViIiNIjosiKS7KeY6Nolu7BIb3SKVz23g6psTRqW3cwWCIi45soS1tPmETGP/9zzWs3V3SrK85qHMKj10++KjLPPXUU6xevZoVK1bwxRdfcNlll7F69eqDh79OnTqVdu3aceDAAUaMGME111xDWlraIa+xadMmZs2axcsvv8x1113He++9x4033tis22JMqKqu9bCtoJyNuaVsyi1lY24ZG/NK2VlYQa3n8Ns7REUIaUkxpCfFkp4US78OyaQnx5CRFEub+GiS46JJiYsiOS76kHAIxgA4XmETGK3FyJEjDzlX4plnnuGDDz4AIDs7m02bNh0WGL169WLIkCEADB8+nO3bt7dUucYEjZo6DzsKy51AyC11H2VsLyg/GAwRAj3SEunbPomLB3WkfXIs6cmxpCc5gZDuhkJL7eIJNmETGMdqCbSUxMTEg8NffPEF8+bN49tvvyUhIYExY8Y0eS5FbGzsweHIyEgOHDjQIrUa0xrV1nnYXljBptxSNuWVuS2HMrYWlFFT5wSDCHRvl0Df9slcPKgD/Tok07dDEn0yksKiJeAvYRMYgZKcnExpadN3uywuLiY1NZWEhATWr1/PwoULW7g6Y1ovX4OhW2oCfdsncf6A9vTrkES/Dsn0yUgiPsaCoblZYPhZWloa55xzDqeeeirx8fF06NDh4LyxY8fywgsvMHDgQPr378+ZZ54ZwEqNCZzaOg/r95aybOd+lu8sYu3uEguGVihk7umdmZmpjW+gtG7dOgYOHBigilpeuG2vCV6FZVUs21nEsp37WbZjP9/lFHOgpg6A9smxnNalDX07JNO3vRsM7RNJiLHft/4gIktVNdOXZe0TMMb4VX3rYfnO/QdDYkdhBeAckTS4cwrjR3RjWI9UhnVvS5e28Xapm1bKAsMY02xUlZz9B1iZU8R3OcWsyC5i9a5iKqqd1kNGcqxzVvLI7gzrkcppXdpYJ3QQscAwxpywgrIqvsspYmV28cGQ2FdeDUBMVASDOqVwXWY3hnZvy7DuqXRNtdZDMLPAMMb4pLrWw/Kd+1mR3dB62FXkHOIdIdC3fTIXDGjPGd3ackbXtvTvmExMVMhfEDusWGAYY44ot6SSLzbkMX99Pl9vLqCsqhaArqnxDOnellvO7sEZXdtyapc2JMba10mos0/YGHNQnUdZkb2fz9c7IbF2j3M5nU5t4rj8jM6M6Z9BZo9U0pJij/FKJhT5NTBEZCzwVyASeEVVn2o0vwcwFcgA9gE3qmqOO68OWOUuulNVr/Bnra1FUlISZWVlgS7DhJHCsiq+3JTP/PX5fLkpn6KKGiIjhOHdU/n52AGcPyCD/h2Sre/B+C8wRCQSeA64CMgBlojIHFVd67XYH4Hpqvq6iHwf+D1wkzvvgKoO8Vd9xoQrVWVjbhn/WbOXzzfksSK7CFVIT4rhggEdOH9ABueekkGbhOhAl2paGX+2MEYCm1V1K4CIvAWMA7wDYxDwE3d4PvChH+sJiClTptCtWzfuu+8+AB5//HGioqKYP38++/fvp6amhieffJJx48YFuFITyjweZXl2Ef9Zs5e5a/ay3T0P4oyubXjwgr58f0B7Tu3cxi66Z47Kn4HRBcj2Gs8BRjVaZiVwNc5uq6uAZBFJU9VCIE5EsoBa4ClV/bDxG4jIZGAyQPfux7jb1L+mwN5VR1/meHU8DS556qiLjB8/noceeuhgYMyePZu5c+fywAMPkJKSQkFBAWeeeSZXXHGFNflNs6qu9fDt1kL+s2Yvn67NJa+0iqgI4aw+adxxbm8uHtSB9ilxgS7TBJFAd3r/FPibiEwCvgR2AXXuvB6quktEegOfi8gqVd3ivbKqvgS8BM6lQVqubN8NHTqUvLw8du/eTX5+PqmpqXTs2JGHH36YL7/8koiICHbt2kVubi4dO3YMdLkmyJVX1bJgYz5z1+zl8/V5lFbWkhATyZj+GfxgcEfG9G9Pm3jb1WROjD8DYxfQzWu8qzvtIFXdjdPCQESSgGtUtcidt8t93ioiXwBDgUMC47gcoyXgTz/60Y9499132bt3L+PHj2fmzJnk5+ezdOlSoqOj6dmzZ5OXNTfGF3Ue5dO1uby7NJsvNxVQXeuhXWIMl5zakYsHdWR033Q7m9o0C38GxhKgr4j0wgmK64GJ3guISDqwT1U9wC9wjphCRFKBClWtcpc5B3jaj7X61fjx47nzzjspKChgwYIFzJ49m/bt2xMdHc38+fPZsWNHoEs0Qaiypo4Plu/i5S+3srWgnM5t4rhhVHd+MLgjmT1SiYq0k+ZM8/JbYKhqrYjcD8zFOax2qqquEZEngCxVnQOMAX4vIoqzS+o+d/WBwIsi4gEicPow1h72JkFi8ODBlJaW0qVLFzp16sQNN9zA5ZdfzmmnnUZmZiYDBgwIdIkmiBQfqGHmoh1M+7/t5JdWcWqXFP42cShjB3e0kDB+ZZc3DyHhtr3hZm9xJa9+vZU3F+2kvLqOc/umc/d5fTi7T5odMGFOmF3e3JgQsim3lBe/3Mo/VuyizqP88PTOTP5eb07t0ibQpZkwY4FhTCu1ZPs+XlywhXnr8oiLjmDiyO7ccW5vurVLCHRpJkyFfGCoalg010Nl16KBRVsLeXruBpbu2E9qQjQPXtCXW87uSbvEmECXZsJcSAdGXFwchYWFpKWF9j5eVaWwsJC4ODsJK5htKyjnqX+tY+6aXDqmxPH45YO4bkQ3uzWpaTVC+l9i165dycnJIT8/P9Cl+F1cXBxdu3YNdBnmBBRVVPPMZ5uZsXA70ZERPHJRP+44tzfxMXbuhGldQjowoqOj6dWrV6DLMKZJ1bUeZizcwTOfbaK0sobrMrvxk4v62eU6TKsV0oFhTGukqvxnbS6//2Qd2wsrGH1KOr+6bCADO6UEujRjjsoCw5gWtCqnmN98vJbF2/ZxSvskpk0awZj+GSHdx2ZChwWGMS1gT/EB/uffG3h/+S7SEmP4zZWnMmFENzsz2wQVCwxj/KimzsPf52/h+QWb8SjcfV4f7j2/DylxdsVYE3wsMIzxk5z9FTwwaznLdhZx2emdmDJ2gJ10Z4KaBYYxfvCvVXv4+Xvf4VF4ZsJQrjijc6BLMuakWWAY04wqa+p48uO1vLFwJ2d0bcMzE4bSIy0x0GUZ0ywsMIxpJpvzSrn/zeWs31vK5O/15qcX9ycmyjq1TeiwwDDmJKkq72Tl8P/mrCYxJoppt47g/P7tA12WMc3OAsOYk1BaWcOvPljNnJW7ObtPGv87foidqW1ClgWGMSdoZXYRP561nF1FB/jpxf24Z8wpREbYCXgmdFlgGHOcPB7l1a+38Yd/r6d9cixvTz6TzJ7tAl2WMX5ngWHMcSgsq+KRd1byxYZ8fjC4A3+45nTaJth9Kkx4sMAwxkff5RRx94ylFJRX85txg7nxzB52DSgTViwwjPHBu0tz+OUHq8hIiuX9e862+2mbsGSBYcxR1NR5+O3H63jtm+2c3SeNZycMJS0pNtBlGRMQFhjGHEF+aRX3vbmMxdv2cfvoXvzikgF2dVkT1iwwjGnCyuwi7n5jKfsrqvnf8UO4cmiXQJdkTMBZYBjTyDtZ2fzqw9VkJMXy7t3WX2FMPQsMY1w1dR6e/Ggtr3+7g3NOSePZCcNol2iHzBpTzwLDGNz+ipnLWLx9H3ee24ufj7X+CmMas8AwYW9FtnN+RdGBav56/RDGDbH+CmOaYoFhwtrsJdk8+uFq2qfE8t49ZzO4s/VXGHMkFhgmLKkq/zN3A3//YgujT0nn2QlDSbX+CmOOygLDhJ3aOg+//GAVs7NymDiqO09cMdj6K4zxgQWGCSuVNXXc/+Zy5q3L5YEL+vLwhX3telDG+MgCw4SN4ooa7pi+hKwd+/nNuMHcdFbPQJdkTFCxwDBhIbekkptfXczWgjKenTCUH57eOdAlGRN0LDBMyNuaX8ZNry6mqKKa124dyTmnpAe6JGOCkl97+kRkrIhsEJHNIjKlifk9ROQzEflORL4Qka5e824RkU3u4xZ/1mlC18rsIq594Vsqa+p4a/JZFhbGnAS/BYaIRALPAZcAg4AJIjKo0WJ/BKar6unAE8Dv3XXbAY8Bo4CRwGMikuqvWk1o+mpTPhNeXkhCTCTv3nM2p3W1cyyMORn+bGGMBDar6lZVrQbeAsY1WmYQ8Lk7PN9r/g+AT1V1n6ruBz4FxvqxVhNi5qzczW2vLaF7uwTeu+dseqUnBrokY4KePwOjC5DtNZ7jTvO2ErjaHb4KSBaRNB/XRUQmi0iWiGTl5+c3W+EmuL32f9t48K3lDO2Wytt3nUWHlLhAl2RMSAj02Uo/Bc4TkeXAecAuoM7XlVX1JVXNVNXMjIwMf9VogoSq8qf/bODxf67lwoEdmH77SNrERwe6LGNChj+PktoFdPMa7+pOO0hVd+O2MEQkCbhGVYtEZBcwptG6X/ixVhPk6jzKox+uZtbinVyX2ZXfXXWanb1tTDPz5/+oJUBfEeklIjHA9cAc7wVEJF1E6mv4BTDVHZ4LXCwiqW5n98XuNGMOU1vn4WfvrGTW4p3cM6YPf7jmdAsLY/zAb/+rVLUWuB/ni34dMFtV14jIEyJyhbvYGGCDiGwEOgC/ddfdB/wGJ3SWAE+404w5RE2dh4feXsH7y3fxyEX9+PnYAXapD2P8RFQ10DU0i8zMTM3Kygp0GaYFVdd6+PGsZcxdk8uUSwZw93l9Al2SMUFHRJaqaqYvy9qZ3iYoVdbUcd/MZXy2Po9f/3AQt4/uFeiSjAl5Fhgm6FTW1HHn9Cy+2lTAb648lZvO7BHokowJCxYYJqhUVNdy+2tZLNxWyB+uOY3xI7oHuiRjwoYFhgkaZVW13DZtCVk79vGnH53B1cO6HnslY0yzscAwQaGksoZJUxezMqeYv14/lMvPsMuTG9PSLDBMq1dUUc3NUxezbk8Jz00cythTOwW6JGPCkgWGadX2lVdz4yuL2JxXxgs3DueCgR0CXZIxYcsCw7Ra+aVV3PDKQnYUVvDyLZmc18+uF2ZMIFlgmFYpt6SSiS8vZHdRJdMmjeBsu/GRMQFngWFandySSq5/aSF5JZW8dusIRvVOC3RJxhgsMEwr4x0Wr982ksye7QJdkjHG5dPFB0XkfRG5zOvKssY0OwsLY1o3XwPg78BEYJOIPCUi/f1YkwlDuSWVTLCwMKZV8ykwVHWeqt4ADAO2A/NE5BsRuVVE7JZm5qTUh0VuSSWvWVgY02r5vIvJvdf2JOAOYDnwV5wA+dQvlZmwkNcoLEZYWBjTavnU6S0iHwD9gRnA5aq6x531tojYTSjMCclz+yz2uruhLCyMad18PUrqGVWd39QMX2+8YYy3vJJKrn/ZwsKYYOLrLqlBItK2fsS91/a9/inJhLqDYVFsYWFMMPE1MO5U1aL6EVXdD9zpl4pMSMsrqWSCGxav3WphYUww8TUwIkVE6kdEJBKI8U9JJlTllTphsccNi5G9LCyMCSa+9mH8G6eD+0V3/C53mjE+ySt1joaysDAmePkaGD/HCYl73PFPgVf8UpEJOfmlVQfDYtqkERYWxgQpnwJDVT3A8+7DGJ/tK6/mhlecq87ahQSNCW6+nofRF/g9MAiIq5+uqr39VJcJAcUVNdz06iJ2FFYwbZKFhTHBztdO72k4rYta4HxgOvCGv4oywa+sqpZbpi1mY24pL9403O5nYUwI8DUw4lX1M0BUdYeqPg5c5r+yTDCrqK7ltmlLWLWrmL9NHMaY/u0DXZIxphn42uld5V7afJOI3A/sApL8V5YJVpU1dUyevpSsHfv46/VD+cHgjoEuyRjTTHxtYTwIJAAPAMOBG4Fb/FWUCU7VtR7unbmMrzcX8PS1Z3D5GZ0DXZIxphkds4XhnqQ3XlV/CpQBt/q9KhN0aus8PDBrOZ+vz+N3V53GtcO7BrokY0wzO2YLQ1XrgNEtUIsJUnUe5SezV/LvNXt57PJBTBzVPdAlGWP8wNc+jOUiMgd4Byivn6iq7/ulKhM0PB5lynvfMWflbn4+dgC3ntMr0CUZY/zE18CIAwqB73tNU8ACI4ypKv9vzmreWZrDgxf05Z4xfQJdkjHGj3w909v6LcwhVJUnP17HGwt3ctd5vXnowr6BLskY42e+nuk9DadFcQhVva3ZKzJB4Y//2cCrX29j0tk9mTJ2AF4XMzbGhChfd0l95DUcB1wF7G7+ckwwePazTTw3fwsTRnbjscsHWVgYEyZ83SX1nve4iMwCvj7WeiIyFvgrEAm8oqpPNZrfHXgdaOsuM0VVPxGRnsA6YIO76EJVvduXWo1/vfLVVv706UauHtqF3155moWFMWHE1xZGY32Bo17vwT1/4zngIiAHWCIic1R1rddijwKzVfV5ERkEfAL0dOdtUdUhJ1if8YM3Fu7gyY/XcdlpnXj62tOJiLCwMCac+NqHUcqhfRh7ce6RcTQjgc2qutV9jbeAcYB3YCiQ4g63wXZztVrvLs3h0Q9Xc8GA9vxl/BCiIn29SIAxJlT4uksq+QReuwuQ7TWeA4xqtMzjwH9E5MdAInCh17xeIrIcKAEeVdWvGr+BiEwGJgN0724ni/nLR9/t5r/eXcnoU9J57oZhxERZWBgTjnz6ny8iV4lIG6/xtiJyZTO8/wTgNVXtClwKzHAvcrgH6K6qQ4GfAG+KSErjlVX1JVXNVNXMjIyMZijHNDZvbS4PvbWC4T1Seenm4cRFRwa6JGNMgPj6U/ExVS2uH1HVIuCxY6yzC+jmNd7VnebtdmC2+5rf4hyBla6qVapa6E5fCmwB+vlYq2kmX23K596ZyxjcOYWpk0aQEHOiXV7GmFDga2A0tdyxvj2WAH1FpJeIxADXA3MaLbMTuABARAbiBEa+iGS4neaISG+cTvatPtZqmsHibfu4c3oWvTMSef22kSTHRQe6JGNMgPn6kzFLRP6Mc9QTwH3A0qOtoKq17r0z5uIcMjtVVdeIyBNAlqrOAR4BXhaRh3E6wCepqorI94AnRKQG8AB3q+q+4946c0JWZBdx22tL6NI2njfuGEXbhJhAl2SMaQVE9bATuA9fSCQR+DVOp7QCnwK/VdXyo67YgjIzMzUrKyvQZQS9tbtLuP6lb2mbEMPsu86iY5u4Y69kjAlaIrJUVTN9WdbXo6TKgSknVZVp9TbnlXLTq4tIjI1i5h2jLCyMMYfw9SipT0Wkrdd4qojM9VtVpsXtKCxn4suLEBFm3jGKbu0SAl2SMaaV8bXTO909MgoAVd3PMc70NsFjV9EBJr68iJo6DzPvGEXvDLtduzHmcL4Ghse97hMA7rWejt35YVq9vJJKbnh5ISWVNcy4fRT9O57IOZrGmHDg61FSvwK+FpEFgADn4p5hbYJXQVkVN7yyiLzSKmbcPopTu7Q59krGmLDla6f3v0UkEycklgMfAgf8WJfxs/3l1dz4yiKy91cwbdJIhvdIDXRJxphWzteLD94BPIhztvYK4EzgWw69ZasJEsUVNdz46iK2FpQz9ZYRnNUnLdAlGWOCgK99GA8CI4Adqno+MBQo8ldRxn9KKmu4eeoiNuWW8dJNwxndNz3QJRljgoSvgVGpqpUAIhKrquuB/v4ry/hDWVUtk6YuZu2eEv5+wzDG9LcD3YwxvvO10zvHPQ/jQ+BTEdkP7PBXUab5VVTXctu0JazMKea5icO4cFCHQJdkjAkyvnZ6X+UOPi4i83FudvRvv1VlmtWB6jpufy2LrB37eGbCUMae2jHQJRljgtBxX69aVRf4oxDjH5U1dUyekcXCbYX85boh/PD0zoEuyRgTpOzWaSGsqraOe95YylebCnj6mtO5cmiXQJdkjAliFhghqrrWw30zlzN/Qz6/u+o0fpTZ7dgrGWPMUVhghKDaOg8PvrWceetyeWLcYCaOsvudG2NOngVGiKnzKA/PXsm/Vu/l1z8cxM1n9Qx0ScaYEGGBEULqPMrP3lnJP1fu5heXDOD20b0CXZIxJoRYYIQIVeVXH6zi/eW7+OnF/bjrvD6BLskYE2IsMEKAqvLf/1zLW0uyuf/8U7j/+30DXZIxJgRZYAQ5VeXpuRt47Zvt3D66F49c3C/QJRljQpQFRpD72+ebef6LLUwc1Z1HLxuIiAS6JGNMiLLACGKvfLWVP326kauHduHJcadaWBhj/MoCI0i9sXAHT368jstO68TT155ORISFhTHGvywwgtC7S3N49MPVXDCgPX8ZP4SoSPsYjTH+Z980Qeaj73bzX++uZPQp6Tx3wzBiouwjNMa0DPu2CSLz1uby0FsrGN4jlZduHk5cdGSgSzLGhBELjCDx1aZ87p25jMGdU5g6aQQJMcd9ZXpjjDkpFhhBYPG2fdw5PYveGYm8fttIkuOiA12SMSYMWWC0ciuyi7jttSV0aRvPG3eMom1CTKBLMsaEKQuMVmzt7hJufnUR7RJjmHnHmaQnxQa6JGNMGLPAaKW2FZRz06uLSIyNYuYdo+jYJi7QJRljwpwFRiuUV1rJzVMXocAbd4yiW7uEQJdkjDEWGK1NaWUNk6YuoaC0mqmTRtAnIynQJRljDGCB0apU1dZx14ylbMwt5fkbhzGkW9tAl2SMMQfZwfythMej/GT2Sr7ZUsifrzuDMf3bB7okY4w5hF9bGCIyVkQ2iMhmEZnSxPzuIjJfRJaLyHcicqnXvF+4620QkR/4s85AU1We+GgtH3+3h19cMoCrh3UNdEnGGHMYv7UwRCQSeA64CMgBlojIHFVd67XYo8BsVX1eRAYBnwA93eHrgcFAZ2CeiPRT1Tp/1RtIzy/YcvAGSJO/1zvQ5RhjTJP82cIYCWxW1a2qWg28BYxrtIwCKe5wG2C3OzwOeEtVq1R1G7DZfb2Q805WNk//ewPjhnTmV5faDZCMMa2XPwOjC5DtNZ7jTvP2OHCjiOTgtC5+fBzrIiKTRSRLRLLy8/Obq+4W8/n6XKa8v4pz+6bzP9eeYfe0MMa0aoE+SmoC8JqqdgUuBWaIiM81qepLqpqpqpkZGRl+K9Iflu3cz70zlzGoUwrP3zjcLlNujGn1/HmU1C6gm9d4V3eat9uBsQCq+q2IxAHpPq4btDbnlXHba0vokBLHtFtHkBRrB6sZY1o/f/6sXQL0FZFeIhKD04k9p9EyO4ELAERkIBAH5LvLXS8isSLSC+gLLPZjrS0mt6SSW6YuJipCmH7bSLs+lDEmaPjtp62q1orI/cBcIBKYqqprROQJIEtV5wCPAC+LyMM4HeCTVFWBNSIyG1gL1AL3hcIRUsUHarhl6mKKKqp5+66z6JGWGOiSjDHGZ+J8Pwe/zMxMzcrKCnQZR1RZU8fNUxezfOd+pk0ayei+6YEuyRhjEJGlqprpy7K287wFqCqPvLOSxdv28cyEoRYWxpigZIfmtIDnF2zh4+/2MOWSAVxxRudAl2OMMSfEAsPP5m/I43/mbuCKMzpzl53FbYwJYhYYfrStoJwHZi1nYMcU/nDN6XYWtzEmqFlg+ElZVS2Tp2cRFSG8eNNw4mMiA12SMcacFOv09gOPR3lk9gq2FpQz47aRreOOeR4PVBRC6W4o2XPoc2UJoOB9xNzB4frpeuj02GRISIPEdEhoBwnpznj9tPh2EGn/vIwJJfY/2g+em7+ZuWty+fUPB3H2KX48IkoVairgwH6o2AcH9kF5AZTuOTwUSvaAp+bQ9SUCEttDfFtAQMR5hkbDeM13FW6C8kKoKj5yfXFtvUIlHZLaQ3JH55HUEZI7OM+JGRYuxgQB+1/azOatzeXP8zZy1dAu3HZOzxN7kdpqKNgIeeugbG9DGFTsOzQcKvZBXVXTrxGdAMmdIKUzdDsTUjpBcmdnPKWzMy+pw8l/UddWu7UUOo/ygoZh72n7t0P2IqgoOPw1JMIJjaQOhwZKYjrEJEFskvucfPh4ZPTJ1W+M8ZkFRjPakl/Gw2+vYHDnFH5/9WnH7uRWhbJcyF0NuWucx97VULABPLUNy0kkxKc6u37i20FqD+g8FBJSnfH66QntnF/0yR2dX/ct0ckeFdPwJe+L2mooz4PSXCcMS/d4DbuPPSuhLI+Du8GOJjLWK0BSnBCJS4G4Ns544+HYNs54XIo7rQ1Ex7fM38qYIGeB0UxKKmu4c3oWMVERvHhTJnHRjTq5a6shb60bDKsbQqKisGGZlC7QYTD0uxg6nArtBzmtgdgUiAiR4xOiYqBNV+dxNHW1UFkEVaVQXQZVZe7zUcarSp1HyS7nb11ZAlUloJ6jv1dElBM0sclOoNSHzsFp9UHkzouO55BdeAfD5gi79UQgKhZiEp1gi0l0HtGJzt/DmCBhgdEMPB7lJ2+vYEdhBTPvGEWXtvENMwu3wNJpsOLNhnCIiocOg2DAZU4wdBjshENCu8BsQGsUGeXskko8yT4gVagud4KjsrghRCqLnUdViRMyle5z/XjpHsjf0DCtrrp5tquxiOjDg6R+vKnWUmyK03o8OOw+xyRaK8n4nQVGM/jrZ5uYty6Pxy8fxJm905zWxPqPnKDY9qXzC7b/pTD4Kuh4OrTrBRF2mG2LEHF2WcUmOa21E1Vb1RA2NQdo+ugxbXR0GQ3T6qqc4Kouc5+9hysOn1eS4waZG3LHuvamRDYKlzaHPw6Z7g4nd3L6jyxsjA8sME7S3DV7+etnm7h2eFduGaDw6WOwYiaU50Pb7vD9X8PQG33fx29ap6hYSMpwHi2t/mi4Q1pIJe4uu/rh4kOHK4th39aGdapLj/z60YnOj5jUnu5zr4bnNt3sCDZzkP1LOAmbckv5r7ezuDtjDT+reBF5doHzS6//JTD8VuhzvrUkzMkTadhVdaKtJE/dobvi6gOnZDfs2wb7t0HBJtj06aFH3kkktO12aIgku0ewJbZ3WicJaRYqYcI+5RNUsncLi179HZ9FzCO9tAikK4z5JQy76eR2fRjjDxHukXbxqUdfzuNx+m/2b3ODZHvD8JoPnMO6DyNO/1tihvvwCpP6fqjGu8RiU0I/ZDweZ09DCAVqaGxFC/N8+WeSPn+CCQql3c6Hc++CvhdZa8IEv4gIaNPFefQcffj8ymIoy3cOjS7Pdx5l+Q3D5fmwd5XzXHmUkzqh4VBo7z6V+jCJiHJONK2rcQ4xr6v2Gq5pmFc/7KkFxFkvItJpGUVEOdtzcNh9lghnOCrOOZk0qUPDI7mjMy02xbd+naoyKNrhBqv7qA/aoh1O3ZGx0H4gdDyt4dFhsLOtQcYC43iowmdPEPH1n/ln3ZlUf/8Jrjl/VKCrMqbl1H+pp59y7GVrq9wTOQsa9bN47xYrdq4WUFnsnJNUsMnZVebxOL/KI6IhMsZrONr50o+McYaj4yHSDRhV5+AAT50TIOpxDkDx1HpNr2sYrjngBF9TR8BFxbtXIvAOkw7O63mHQ3neoevFpjh9Qe0HOrum23SF4mwnRDd8AstnNCzbtkejEDnV6fdsxQcgWGD4yuOBub+ARS/wfsRFzO74MLPGjAx0Vca0XlGxDa2V1krV2c1WluecPFqW55w8Wpbb8Mjf4BztWFnktE5Sujonz/b7QcPBAqk9nf6d+NQjf+GrOq+9dxXkrnKe966G9R9z8Gi7uDaQ3t+9qkGCc0BCTIJz5YaYJK/hxEOfE9Kg/QC//7ksMHzhqYN/PgDL32B19xv5ycZLmHXRALtcuTHBTtz+l4R2x/7Cral0AuNET7YUcS7Rk9LJOTm3XnU55K5tCJHCzQ0HJNSUNxx6XXvgyK/dZTjc+fmJ1XUcLDCOpa4G3p8Ma96ndvTPuHXhKM7sncRZfdICXZkxpiVFx/nndWMSodsI53E0Ho9zeHVNRcP5OvXD0fFHX7eZWGAcTU0lvDMJNv4LLvxvpjOO/LK1PDuxX6ArM8aEm4iIhpNQA1VCwN65tasuh1njnbC49I9Ujvoxzy/Ywlm905yzuY0xJsxYYDSlshhmXO10dF35PIy8k5mLdpJfWsVDF/YNdHXGGBMQtkuqsYp9MOMq52qy106FwVdRWVPHCwu2cHafNEZZ68IYE6asheGtNBdeu8y5cdH1bzoXCwTeWLiD/NIqHrzAWhfGmPBlLYx6RdkwfZxznPQN70Dv8wA4UF3HCwu2WuvCGBP2rIUBzj0rpl3inJV60wcHwwJg5qIdFJRV8dCFdmSUMSa8WQtj3zaYdqlzeYBb5kDnIQdnOa2LLZxzShoje9nNjYwx4c0CI6Uz9Pk+nPOAc/0XL07roprnrXVhjDEWGETFwlXPHza5orqWFxZsYfQp6Yzoaa0LY4yxPowjmLlwJwVl1Txo510YYwxggdEka10YY8zhLDCa8MbCHRSWV9tZ3cYY48UCo5GK6lpeXLCVc/umk2mtC2OMOcgCo5EZ31rrwhhjmuLXwBCRsSKyQUQ2i8iUJub/RURWuI+NIlLkNa/Oa94cf9ZZr6K6lhe/dFoXw3tY68IYY7z57bBaEYkEngMuAnKAJSIyR1XX1i+jqg97Lf9jYKjXSxxQ1SH+qq8pM77dwT5rXRhjTJP82cIYCWxW1a2qWg28BYw7yvITgFl+rOeoyqusdWGMMUfjz8DoAmR7jee40w4jIj2AXoD3TWnjRCRLRBaKyJV+q9I1Y2F968LO6jbGmKa0ljO9rwfeVdU6r2k9VHWXiPQGPheRVaq6xXslEZkMTAbo3r37Cb95eVUtL325le/1y2B4j9QTfh1jjAll/mxh7AK6eY13dac15Xoa7Y5S1V3u81bgCw7t36hf5iVVzVTVzIyMjBMudLr1XRhjzDH5MzCWAH1FpJeIxOCEwmFHO4nIACAV+NZrWqqIxLrD6cA5wNrG6zYHp3WxhfP6ZTCsu7UujDHmSPy2S0pVa0XkfmAuEAlMVdU1IvIEkKWq9eFxPfCWqqrX6gOBF0XEgxNqT3kfXdWcyqpqOatPGnec29sfL2+MMSFDDv2eDl6ZmZmalZUV6DKMMSaoiMhSVc30ZVk709sYY4xPLDCMMcb4xALDGGOMTywwjDHG+MQCwxhjjE8sMIwxxvjEAsMYY4xPLDCMMcb4JGRO3BORfGDHSbxEOlDQTOUEG9v28BXO2x/O2w4N299DVX26GF/IBMbJEpEsX892DDW27eG57RDe2x/O2w4ntv22S8oYY4xPLDCMMcb4xAKjwUuBLiCAbNvDVzhvfzhvO5zA9lsfhjHGGJ9YC8MYY4xPLDCMMcb4JOwDQ0TGisgGEdksIlMCXU9LE5HtIrJKRFaISEjfgUpEpopInois9prWTkQ+FZFN7nPI3qf3CNv/uIjscj//FSJyaSBr9BcR6SYi80VkrYisEZEH3ekh//kfZduP+7MP6z4MEYkENgIXATk49yGf4K/bwbZGIrIdyFTVkD+BSUS+B5QB01X1VHfa08A+VX3K/cGQqqo/D2Sd/nKE7X8cKFPVPwayNn8TkU5AJ1VdJiLJwFLgSmASIf75H2Xbr+M4P/twb2GMBDar6lZVrQbeAsYFuCbjJ6r6JbCv0eRxwOvu8Os4/5FC0hG2Pyyo6h5VXeYOlwLrgC6Ewed/lG0/buEeGF2AbK/xHE7wDxnEFPiPiCwVkcmBLiYAOqjqHnd4L9AhkMUEyP0i8p27yyrkdsk0JiI9gaHAIsLs82+07XCcn324B4aB0ao6DLgEuM/dbRGW1Nk/G277aJ8H+gBDgD3AnwJajZ+JSBLwHvCQqpZ4zwv1z7+JbT/uzz7cA2MX0M1rvKs7LWyo6i73OQ/4AGc3XTjJdffx1u/rzQtwPS1KVXNVtU5VPcDLhPDnLyLROF+YM1X1fXdyWHz+TW37iXz24R4YS4C+ItJLRGKA64E5Aa6pxYhIotsJhogkAhcDq4++VsiZA9ziDt8C/COAtbS4+i9L11WE6OcvIgK8CqxT1T97zQr5z/9I234in31YHyUF4B5K9r9AJDBVVX8b2Ipajoj0xmlVAEQBb4by9ovILGAMzmWdc4HHgA+B2UB3nMvjX6eqIdkxfITtH4OzS0KB7cBdXvv0Q4aIjAa+AlYBHnfyL3H25Yf053+UbZ/AcX72YR8YxhhjfBPuu6SMMcb4yALDGGOMTywwjDHG+MQCwxhjjE8sMIwxxvjEAsOYVkBExojIR4Guw5ijscAwxhjjEwsMY46DiNwoIovd+we8KCKRIlImIn9x7zXwmYhkuMsOEZGF7sXdPqi/uJuInCIi80RkpYgsE5E+7ssnici7IrJeRGa6Z+ga02pYYBjjIxEZCIwHzlHVIUAdcAOQCGSp6mBgAc4Z1ADTgZ+r6uk4Z9nWT58JPKeqZwBn41z4DZyriD4EDAJ6A+f4eZOMOS5RgS7AmCByATAcWOL++I/HuVidB3jbXeYN4H0RaQO0VdUF7vTXgXfca3d1UdUPAFS1EsB9vcWqmuOOrwB6Al/7fauM8ZEFhjG+E+B1Vf3FIRNFft1ouRO93k6V13Ad9v/TtDK2S8oY330GXCsi7eHg/aB74Pw/utZdZiLwtaoWA/tF5Fx3+k3AAveOZzkicqX7GrEiktCSG2HMibJfMMb4SFXXisijOHcojABqgPuAcmCkOy8Pp58DnMtlv+AGwlbgVnf6TcCLIvKE+xo/asHNMOaE2dVqjTlJIlKmqkmBrsMYf7NdUsYYY3xiLQxjjDE+sRaGMcYYn1hgGGOM8YkFhjHGGJ9YYBhjjPGJBYYxxhif/H9iMx1f5TIaMAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example of plotting accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load models (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This only needs to be run if you haven't already run the \"Creating the models\" section of this notebooks\n",
    "# (First run data prep. and generation-function, then this cell)\n",
    "\n",
    "# eng2lang_model = generate_encoder_decoder_model(regularization=False, load_weights=eng2lang_model_file)\n",
    "# lang2eng_model = generate_encoder_decoder_model(regularization=False, load_weights=lang2eng_model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(texts):\n",
    "    tokenized = tokenizer.texts_to_sequences(texts)\n",
    "    X = np.array(keras.preprocessing.sequence.pad_sequences(tokenized, padding=\"post\", maxlen=max_sentence_len))\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eng2lang_predict(sentence):\n",
    "    X_new = preprocess([sentence])\n",
    "    prediction = np.argmax(eng2lang_model.predict(X_new), axis=-1)\n",
    "    return tokenizer.sequences_to_texts([prediction[prediction != 0]])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lang2eng_predict(sentence):\n",
    "    X_new = preprocess([sentence])\n",
    "    prediction = np.argmax(lang2eng_model.predict(X_new), axis=-1)\n",
    "    return tokenizer.sequences_to_texts([prediction[prediction != 0]])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eng2eng_predict(sentence):\n",
    "    return lang2eng_predict(eng2lang_predict(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I thought that book was difficult to read.\n",
      "Keep your hands off my daughter!\n",
      "I would go at 10.\n",
      "I'm all ears.\n",
      "This winter is warm.\n",
      "Beautiful day, isn't it?\n",
      "It is necessary for you to start at once.\n",
      "I'll give you five dollars.\n",
      "When I call on you, I'll let you know in advance.\n",
      "She looked very beautiful in her new dress.\n"
     ]
    }
   ],
   "source": [
    "# Example sentences from the dataset\n",
    "for i in range(10):\n",
    "    print(np.random.choice(english_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sentence: \n",
      " I can't do such a thing like you did.\n",
      "1) Translated to language: \n",
      " i like do in a out like you did\n",
      "2) Translated from language: \n",
      " i wouldn't better such a thing about you did\n",
      "3) Translated to language and back: \n",
      " i can't do such a position yen you did\n",
      "\n",
      "Original sentence: \n",
      " The society made him president.\n",
      "1) Translated to language: \n",
      " the didn't know him there\n",
      "2) Translated from language: \n",
      " the dress made help immediately\n",
      "3) Translated to language and back: \n",
      " the society made him president\n",
      "\n",
      "Original sentence: \n",
      " You don't get up as early as your sister.\n",
      "1) Translated to language: \n",
      " you don't get up as in as your what\n",
      "2) Translated from language: \n",
      " you don't get up as early as your sister\n",
      "3) Translated to language and back: \n",
      " you don't get up as talk as your sister\n",
      "\n",
      "Original sentence: \n",
      " You have a way with women.\n",
      "1) Translated to language: \n",
      " you have a and with and\n",
      "2) Translated from language: \n",
      " you have a way with women\n",
      "3) Translated to language and back: \n",
      " you have a great with women\n",
      "\n",
      "Original sentence: \n",
      " I'm going shopping tomorrow.\n",
      "1) Translated to language: \n",
      " i'm was in\n",
      "2) Translated from language: \n",
      " i'm full myself nine\n",
      "3) Translated to language and back: \n",
      " i'm all from\n",
      "\n",
      "Original sentence: \n",
      " They went down to the country.\n",
      "1) Translated to language: \n",
      " they will him to the out\n",
      "2) Translated from language: \n",
      " let's went down to the other\n",
      "3) Translated to language and back: \n",
      " someone went talking to the country\n",
      "\n",
      "Original sentence: \n",
      " They look happy today.\n",
      "1) Translated to language: \n",
      " they know out him\n",
      "2) Translated from language: \n",
      " now look happy today\n",
      "3) Translated to language and back: \n",
      " they break happy down\n",
      "\n",
      "Original sentence: \n",
      " Have you heard the news yet?\n",
      "1) Translated to language: \n",
      " have you know the tomorrow\n",
      "2) Translated from language: \n",
      " have you heard the news yet\n",
      "3) Translated to language and back: \n",
      " have you heard the water\n",
      "\n",
      "Original sentence: \n",
      " I go to bed about ten.\n",
      "1) Translated to language: \n",
      " i go to out him out\n",
      "2) Translated from language: \n",
      " i go to bed about ten school\n",
      "3) Translated to language and back: \n",
      " i go to bed about ten\n",
      "\n",
      "Original sentence: \n",
      " Yes, as far as I know.\n",
      "1) Translated to language: \n",
      " we as know as i know\n",
      "2) Translated from language: \n",
      " yes as far as i know\n",
      "3) Translated to language and back: \n",
      " yes as far as i know\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    sentence = np.random.choice(english_sentences)\n",
    "    print(\"Original sentence: \\n\", sentence)\n",
    "    print(\"1) Translated to language: \\n\", eng2lang_predict(sentence))\n",
    "    print(\"2) Translated from language: \\n\", lang2eng_predict(sentence))\n",
    "    print(\"3) Translated to language and back: \\n\", eng2eng_predict(sentence))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) Translated to language: \n",
      " he will not be out to do the go\n",
      "2) Translated from language: \n",
      " he will not be able to do the work\n",
      "3) Translated to language and back: \n",
      " he will not be able to do the work\n"
     ]
    }
   ],
   "source": [
    "# Translate custom sentence\n",
    "sentence = \"He will not be able to do the work.\"\n",
    "\n",
    "print(\"1) Translated to language: \\n\", eng2lang_predict(sentence))\n",
    "print(\"2) Translated from language: \\n\", lang2eng_predict(sentence))\n",
    "print(\"3) Translated to language and back: \\n\", eng2eng_predict(sentence))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envs",
   "language": "python",
   "name": "envs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
